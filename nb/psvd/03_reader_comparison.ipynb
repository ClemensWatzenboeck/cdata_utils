{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement between readers\n",
    "\n",
    "Following: \n",
    "Ranganathan, P., Pramesh, C. S., & Aggarwal, R. (2017). Common pitfalls in statistical analysis: Measures of agreement. Perspectives in clinical research, 8(4), 187â€“191. https://doi.org/10.4103/picr.PICR_123_17\n",
    "https://doi.org/10.4103%2Fpicr.PICR_123_17\n",
    "\n",
    "For metric variables ->  ICC\n",
    "\n",
    "For ordinal -> Cohen's Kappa weighted version \n",
    "\n",
    "For categorical -> Cohen's Kappa not weighted version \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True \n",
    "\n",
    "from pathlib import Path\n",
    "import cdata_utils\n",
    "import numpy as np\n",
    "import cdata_utils.utils\n",
    "import datetime\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "#import cdata_utils.preprocess.read_and_clean_tabular\n",
    "from cdata_utils.project_specific.psvd import (\n",
    "    read_and_clean_PSVD_data__BL_consensus,\n",
    "    categorize_PSVD_data,\n",
    "    exclude_patients,\n",
    "    reorder_some_categorical_values, \n",
    "    table1_psvd, \n",
    "    table1_psvd_spleen, \n",
    "    descriptive_df_from_masks, \n",
    "    masks_for_endpoint_1__decompensation, \n",
    "    masks_for_endpoint_2__death,\n",
    "    make_y_delta,\n",
    "    drop_non_numeric_columns,\n",
    "    table_of_valid_entries, \n",
    "    univariate_cox_ph_summary, \n",
    "    normalize_df,\n",
    "    columns_important_variables_BL_FU,\n",
    "    categorize_PSVD_data_, \n",
    "    flatten, \n",
    "    read_and_clean_PSVD_data__BL_FU_consensus,\n",
    ")\n",
    "\n",
    "from cdata_utils.descriptive.basic_stats import (\n",
    "    describe, \n",
    "    convert_bool_bool_to_int,\n",
    ")\n",
    "\n",
    "import cdata_utils.preprocess\n",
    "import cdata_utils.project_specific\n",
    "import cdata_utils.project_specific.psvd\n",
    "\n",
    "\n",
    "import lifelines\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.datasets import load_rossi\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# path info: \n",
    "if \"cwatzenboeck\" in os.getcwd(): # desktop \n",
    "    data_path = Path(\"/home/cwatzenboeck/Dropbox/work/data/livermodel/PSVD/\")\n",
    "    data_path_output=Path(\"/home/cwatzenboeck/data/psvd/output_coxph/\")\n",
    "else: # laptop \n",
    "    data_path = Path(\"/home/clemens/Dropbox/work/data/livermodel/PSVD/\")\n",
    "    # data_path = Path(\"/home/clemens/projects/project_liver_model/data/PSVD\")\n",
    "    \n",
    "\n",
    "    \n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE\n",
    "\n",
    "from cdata_utils.project_specific.psvd import (\n",
    "    rename_columns_by_prefix,\n",
    "    read_renaming_dict\n",
    ")\n",
    "\n",
    "\n",
    "def read_and_clean_PSVD_data__BL_FU_consensus(data_path: Path | str, \n",
    "                                           verbose=False, \n",
    "                                           file_name = \"data_PSVD_unified_1.xlsx\" #\"data_PSVD_orig.xlsx\"\n",
    "                                           ):\n",
    "    data_origin_path = data_path / file_name\n",
    "    dfo = pd.read_excel(data_origin_path)\n",
    "    df = dfo.copy()\n",
    "    df = df.drop(columns=[\"Name\", \"Prename\", \"DOB\"])\n",
    "\n",
    "    # rename inconsistent column names: \n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL_1 \", prefix_new=\"BL1 \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL_2 \", prefix_new=\"BL2 \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL_1\", prefix_new=\"BL1\", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL 1_\", prefix_new=\"BL1 \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL_2\", prefix_new=\"BL2\", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL_\", prefix_new=\"BL \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"BL-\", prefix_new=\"BL \", verbose=verbose)\n",
    "\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU_1 \", prefix_new=\"FU1 \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU_2 \", prefix_new=\"FU2 \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU_1\", prefix_new=\"FU1\", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU 1_\", prefix_new=\"FU1 \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU_2\", prefix_new=\"FU2\", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU_\", prefix_new=\"FU \", verbose=verbose)\n",
    "    df = rename_columns_by_prefix(df, prefix_old=\"FU-\", prefix_new=\"FU \", verbose=verbose)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_BL1_BL2_columns(df, regex_filters, chill=True):\n",
    "    rows = []\n",
    "    for f in regex_filters:\n",
    "        c1 = list(df.filter(regex=\"^BL1.*\"+f).columns)\n",
    "        c2 = list(df.filter(regex=\"^BL2.*\"+f).columns)\n",
    "        if not chill:\n",
    "            assert len(c1) == 1\n",
    "            assert len(c2) == 1\n",
    "            c1 = c1[0]\n",
    "            c2 = c2[0]\n",
    "        rows.append({\"lc1\": len(c1), \"lc2\": len(c2), \"c1\": c1,  \"c2\": c2})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note that one could use the weighted version for ordinal data\n",
    "def cohen_kappa_df(df, c1: str, c2: str):\n",
    "    df_ = df[[c1, c2]].dropna()\n",
    "    y1 = df_[c1]\n",
    "    y2 = df_[c2]\n",
    "    kappa = cohen_kappa_score(y1, y2)\n",
    "    return pd.DataFrame([{\"column 1\": c1, \"column 2\": c2, \"cohen_kappa\": kappa}])\n",
    "\n",
    "\n",
    "def icc_two_columns(df, c1, c2, id_column = \"ID\"):\n",
    "    df_1 = df[[id_column, c1]].rename(columns = {c1: \"Scores\"})\n",
    "    df_2 = df[[id_column, c2]].rename(columns = {c2: \"Scores\"})\n",
    "    df_1[\"Rater\"] = 1\n",
    "    df_2[\"Rater\"] = 2\n",
    "\n",
    "    df_ = pd.concat([df_1, df_2]).reset_index().drop(columns=[\"index\"])\n",
    "    icc = pg.intraclass_corr(data=df_, targets=id_column, raters='Rater',\n",
    "                            ratings='Scores', nan_policy = \"omit\")\n",
    "    return icc\n",
    "\n",
    "\n",
    "def extract_icc_column_as_dict(icc_, mask_column=\"Type\", icc_type = \"ICC2\"):\n",
    "    \n",
    "    _, dct = next(icc_[icc_[mask_column] == icc_type].reset_index().iterrows())\n",
    "    pre = icc_type\n",
    "    dct = {f\"{pre}:  {k}\": dct[k] for k in dct.keys() if k != \"index\"}\n",
    "    return dct\n",
    "\n",
    "def icc_stats_df(df_pairs, icc_type = \"ICC2\", calculate_icc=False, calculate_kappa=False, calculate_kappa_liniar = False, save_sets=False): \n",
    "    rows= []\n",
    "    for i, (_, row) in enumerate(df_pairs.iterrows()):\n",
    "        c1 = row[\"c1\"]\n",
    "        c2 = row[\"c2\"]\n",
    "        \n",
    "        dct = {\"c1\": c1, \"c2\": c2}\n",
    "        print(f\"Comparing: '{c1}' vs '{c2}'\")\n",
    "        if save_sets:\n",
    "            dct = dct | {\"set c1\": set(df[c1]), \n",
    "                         \"set c2\": set(df[c2])}\n",
    "        \n",
    "        \n",
    "        df_ = df[[c1, c2]].dropna()\n",
    "        y1 = df_[c1]\n",
    "        y2 = df_[c2]\n",
    "        \n",
    "        if calculate_kappa:\n",
    "            kappa = cohen_kappa_score(y1, y2)\n",
    "            dct = dct | {\"cohen kappa (not weighted)\": kappa}\n",
    "            \n",
    "        if calculate_kappa_liniar:\n",
    "            kappa_linear  = cohen_kappa_score(y1, y2, weights=\"linear\")\n",
    "            dct = dct | {\"cohen kappa (linear weighted)\": kappa_linear}\n",
    "            \n",
    "        if calculate_icc:\n",
    "            icc_ = icc_two_columns(df, c1, c2)\n",
    "            dct_icc = extract_icc_column_as_dict(icc_, icc_type=icc_type)\n",
    "            dct = dct | dct_icc\n",
    "            dct = dct | {\"ICC all\": icc_}\n",
    "            \n",
    "        rows.append(dct)  \n",
    "        \n",
    "    df_icc_non_metric2 = pd.DataFrame(rows)\n",
    "    return df_icc_non_metric2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = read_and_clean_PSVD_data__BL_FU_consensus(data_path=data_path, file_name = \"data_PSVD_unified_3.xlsx\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regex_filters = [\n",
    "    \"Spleen\",\n",
    "    \"Ascites\",\n",
    "    \"_SPSS\",\n",
    "    \"L-SPSS\",\n",
    "    \"intrahep./LPV/RPV\",\n",
    "    \"extrahep.\",\n",
    "    \"SMV/SV\",\n",
    "    \"PV overall extent\",\n",
    "    #\n",
    "    \"abnormalities\", #\"Intrahepatic portal vein abnormalities\",\n",
    "    ## \"Liver morphology\",\n",
    "    \"segment 1\",\n",
    "    \"segment IV\",\n",
    "    \"Atrophy/hypertrophy complex\",\n",
    "    \"FNH-like lesions\",\n",
    "    \"shunts\",\n",
    "    \"TPMT\", \n",
    "    \"Splanchnic thrombosis\",\n",
    "    \"Intrahepatic portal abnormalities\",\n",
    "    \"Location\"\n",
    "]\n",
    "\n",
    "# categories which work\n",
    "regex_filters_ordinal_categorical = [\n",
    "    \"Ascites\",\n",
    "    \"_SPSS\",\n",
    "    \"L-SPSS\",\n",
    "    \"intrahep./LPV/RPV\",\n",
    "    # \"extrahep.\",\n",
    "    \"SMV/SV\",\n",
    "    ## \"Liver morphology\",\n",
    "    \"segment 1\",\n",
    "    \"segment IV\",\n",
    "    \"Atrophy/hypertrophy complex\",\n",
    "    \"shunts\",\n",
    "        \"extrahep.\",\n",
    "        \"PV overall extent\",  # not sure why this crashes\n",
    "]\n",
    "\n",
    "# categories which need further preprocessing\n",
    "regex_filters_ordinal_categorical_2 = [\n",
    "    \"FNH-like lesions\", \n",
    "    \"Splanchnic thrombosis\",  # needs further preprocessing\n",
    "    \"Intrahepatic portal abnormalities\",  # needs further preprocessing\n",
    "    \"Location\"  # needs further processing\n",
    "]\n",
    "\n",
    "\n",
    "regex_filters_metric = [\n",
    "    \"Spleen\",\n",
    "    \"TPMT\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get dataframe column names with BL1, BL2 for non metric variables\n",
    "df_pairs = get_BL1_BL2_columns(df, regex_filters_ordinal_categorical, chill=True)\n",
    "assert (df_pairs[\"lc1\"] == 1).all(), \"lc1 should be 1\"\n",
    "assert (df_pairs[\"lc2\"] == 1).all(), \"lc2 should be 1\"\n",
    "df_pairs = df_pairs.drop(columns=[\"lc1\", \"lc2\"])\n",
    "df_pairs[\"c1\"] = df_pairs[\"c1\"].apply(lambda x: x[0])\n",
    "df_pairs[\"c2\"] = df_pairs[\"c2\"].apply(lambda x: x[0])\n",
    "# df_extra = pd.DataFrame([\n",
    "#     {\"c1\": \"BL1_Liver morphology (0=normal, 1=abnormal)\",\n",
    "#      \"c2\": \"BL2 Liver morphology\"  \n",
    "#      }])\n",
    "# df_pairs = pd.concat([df_pairs, df_extra]).reset_index().drop(columns=[\"index\"])\n",
    "df_pairs_non_metric = df_pairs.copy()\n",
    "\n",
    "\n",
    "# get dataframe column names with BL1, BL2 for non metric variables\n",
    "df_pairs = get_BL1_BL2_columns(df, regex_filters_ordinal_categorical_2, chill=True)\n",
    "assert (df_pairs[\"lc1\"] == 1).all(), \"lc1 should be 1\"\n",
    "assert (df_pairs[\"lc2\"] == 1).all(), \"lc2 should be 1\"\n",
    "df_pairs = df_pairs.drop(columns=[\"lc1\", \"lc2\"])\n",
    "df_pairs[\"c1\"] = df_pairs[\"c1\"].apply(lambda x: x[0])\n",
    "df_pairs[\"c2\"] = df_pairs[\"c2\"].apply(lambda x: x[0])\n",
    "df_pairs_non_metric_2 = df_pairs.copy()\n",
    "\n",
    "\n",
    "# get dataframe column names with BL1, BL2 for metric variables\n",
    "df_pairs = get_BL1_BL2_columns(df, regex_filters_metric, chill=True)\n",
    "assert (df_pairs[\"lc1\"] == 1).all(), \"lc1 should be 1\"\n",
    "assert (df_pairs[\"lc2\"] == 1).all(), \"lc2 should be 1\"\n",
    "df_pairs = df_pairs.drop(columns=[\"lc1\", \"lc2\"])\n",
    "df_pairs[\"c1\"] = df_pairs[\"c1\"].apply(lambda x: x[0])\n",
    "df_pairs[\"c2\"] = df_pairs[\"c2\"].apply(lambda x: x[0])\n",
    "df_pairs_metric = df_pairs.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_agreement_metric_variables():\n",
    "    ICC_results_metric = []\n",
    "    icc_type = \"ICC2\"\n",
    "\n",
    "    index = 0; \n",
    "    c1, c2  = df_pairs_metric.loc[index,:].to_numpy()\n",
    "    print(\"Comparing: \", c1, \"with \", c2)\n",
    "    # exclude spleenectomy: \n",
    "    m = df[c1] == \"splenectomy\"\n",
    "    m_ = df[c2] == \"splenectomy\"\n",
    "    assert(m == m_).all()\n",
    "    icc_ = icc_two_columns(df[~m].astype({c1: 'float', c2: 'float'}), c1, c2)\n",
    "    dct_icc = extract_icc_column_as_dict(icc_, icc_type=icc_type)\n",
    "\n",
    "    ICC_results_metric.append({\"c1\": c1,\n",
    "                            \"c2\": c2,\n",
    "                            \"ICC all\": icc_} | dct_icc)\n",
    "\n",
    "\n",
    "\n",
    "    index = 1; \n",
    "    c1, c2  = df_pairs_metric.loc[index,:].to_numpy()\n",
    "    print(\"Comparing: \", c1, \"with \", c2)\n",
    "    icc_ = icc_two_columns(df, c1, c2)\n",
    "    dct_icc = extract_icc_column_as_dict(icc_, icc_type=icc_type)\n",
    "\n",
    "    ICC_results_metric.append({\"c1\": c1,\n",
    "                            \"c2\": c2,\n",
    "                            \"ICC all\": icc_} | dct_icc)\n",
    "\n",
    "\n",
    "    ICC_results_metric = pd.DataFrame(ICC_results_metric)\n",
    "    return ICC_results_metric\n",
    "\n",
    "\n",
    "agreement_results_metric = calculate_agreement_metric_variables()\n",
    "agreement_results_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non metric variables which work out of the box\n",
    "df_tmp = pd.DataFrame([{\"c1\": 'BL1_Liver morphology (0=normal, 1=abnormal)', \n",
    "               \"c2\": 'BL2_Liver morphology'}])\n",
    "df_tmp = pd.concat([df_pairs_non_metric, df_tmp])\n",
    "\n",
    "agreement_results_non_metric = icc_stats_df(df_tmp, calculate_kappa=True, calculate_kappa_liniar=True)\n",
    "agreement_results_non_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All variables which need some extra preprocessing: \n",
    "display(df_pairs_non_metric_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "c1, c2 = df_pairs_non_metric_2.iloc[i, :].to_numpy()\n",
    "print(\"c1\", c1, \"\\nc2\", c2)\n",
    "print(\"Unique values: \", set(list(df[c1]) + list(df[c2])))\n",
    "\n",
    "y = df[c1]\n",
    "y1 = np.select([y==0, y==1, y==\"only pv phase\"], [0,1,2], default=np.nan)\n",
    "y = df[c2]\n",
    "y2 = np.select([y==0, y==1, y==\"only pv phase\"], [0,1,2], default=np.nan)\n",
    "kappa = cohen_kappa_score(y1, y2)\n",
    "\n",
    "r = {\"c1\": c1, \n",
    "     \"c2\": c2, \n",
    "     \"cohen kappa (not weighted)\": kappa, \n",
    "     \"notes\": \"The entry 'only pv phase' was treated as a seperate category. \"\n",
    "     }\n",
    "\n",
    "agreement_results_non_metric_other = pd.DataFrame([r])\n",
    "agreement_results_non_metric_other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "c1, c2 = df_pairs_non_metric_2.iloc[i, :].to_numpy()\n",
    "print(\"c1\", c1, \"\\nc2\", c2)\n",
    "print(\"Unique values: \", set(list(df[c1]) + list(df[c2])))\n",
    "\n",
    "y1 = df[c1]\n",
    "y2 = df[c2]\n",
    "\n",
    "# check that non nulls are in the data\n",
    "assert (y1.isnull().any(), y2.isnull().any()) == (False, False) \n",
    "\n",
    "i = 1\n",
    "y1_1 = y1.apply(lambda x: str(i) in str(x))\n",
    "y2_1 = y2.apply(lambda x: str(i) in str(x))\n",
    "\n",
    "i = 2\n",
    "y1_2 = y1.apply(lambda x: str(i) in str(x))\n",
    "y2_2 = y2.apply(lambda x: str(i) in str(x))\n",
    "\n",
    "rows = []\n",
    "rows.append({\"c1\": c1, \"c2\": c2, \n",
    "            \"cohen kappa (not weighted)\": cohen_kappa_score(y1_1, y2_1), \n",
    "            \"notes\": \"Compare '1' vs 'not 1'\" \n",
    "            })\n",
    "\n",
    "rows.append({\"c1\": c1, \"c2\": c2, \n",
    "            \"cohen kappa (not weighted)\": cohen_kappa_score(y1_2, y2_2), \n",
    "            \"notes\": \"Compare '2' vs 'not 2'\" \n",
    "            })\n",
    "\n",
    "\n",
    "agreement_results_non_metric_other_ = pd.DataFrame(rows)\n",
    "agreement_results_non_metric_other = pd.concat([agreement_results_non_metric_other, agreement_results_non_metric_other_]).reset_index().drop(columns=[\"index\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "c1, c2 = df_pairs_non_metric_2.iloc[i, :].to_numpy()\n",
    "print(\"c1\", c1, \"\\nc2\", c2)\n",
    "print(\"Unique values: \", set(list(df[c1]) + list(df[c2])))\n",
    "\n",
    "y1 = df[c1]\n",
    "y2 = df[c2]\n",
    "\n",
    "# check that non nulls are in the data\n",
    "assert (y1.isnull().any(), y2.isnull().any()) == (False, False) \n",
    "\n",
    "rows = []\n",
    "for i in range(1, 5):\n",
    "    y1_ = y1.apply(lambda x: str(i) in str(x))\n",
    "    y2_ = y2.apply(lambda x: str(i) in str(x))\n",
    "    rows.append({\"c1\": c1, \"c2\": c2, \n",
    "                \"cohen kappa (not weighted)\": cohen_kappa_score(y1_, y2_), \n",
    "                \"notes\": f\"Compare '{i}' vs 'not {i}'\" \n",
    "                })\n",
    "\n",
    "\n",
    "agreement_results_non_metric_other_ = pd.DataFrame(rows)\n",
    "agreement_results_non_metric_other = pd.concat([agreement_results_non_metric_other, agreement_results_non_metric_other_]).reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "agreement_results_non_metric_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "c1, c2 = df_pairs_non_metric_2.iloc[i, :].to_numpy()\n",
    "print(\"c1\", c1, \"\\nc2\", c2)\n",
    "print(\"Unique values: \", set(list(df[c1]) + list(df[c2])))\n",
    "\n",
    "y1 = df[c1]\n",
    "y2 = df[c2]\n",
    "assert (y1.isnull().any(), y2.isnull().any()) == (False, False) \n",
    "\n",
    "y1_ = y1!=0\n",
    "y2_ = y2!=0\n",
    "{\"c1\": c1, \"c2\": c2, \n",
    "                \"cohen kappa (not weighted)\": cohen_kappa_score(y1_, y2_), \n",
    "                \"notes\": f\"Compare as binary category (any type) vs. none;   any type (PV, SV, ...) -> 1; 0 -> 0\" \n",
    "                }\n",
    "\n",
    "\n",
    "agreement_results_non_metric_other_ = pd.DataFrame(rows)\n",
    "agreement_results_non_metric_other = pd.concat([agreement_results_non_metric_other, agreement_results_non_metric_other_]).reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "agreement_results_non_metric_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "df_results_all = pd.concat([agreement_results_metric, agreement_results_non_metric, agreement_results_non_metric_other]).reset_index().drop(columns=[\"index\"])\n",
    "df_results_all[['c1', 'c2', 'notes', 'cohen kappa (not weighted)', 'cohen kappa (linear weighted)', 'ICC2:  ICC', \n",
    "                'ICC2:  Description', 'ICC2:  F', 'ICC2:  df1', 'ICC2:  df2', 'ICC2:  pval', 'ICC2:  CI95%']].to_excel(data_path_output / \"reader_comparison_statistics.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
