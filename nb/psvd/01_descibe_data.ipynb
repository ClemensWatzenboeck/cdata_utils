{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import \n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True \n",
    "\n",
    "from pathlib import Path\n",
    "import cdata_utils\n",
    "import numpy as np\n",
    "import cdata_utils.utils\n",
    "import datetime\n",
    "\n",
    "from cdata_utils.utils import integerized\n",
    "\n",
    "import json\n",
    "\n",
    "#import cdata_utils.preprocess.read_and_clean_tabular\n",
    "from cdata_utils.project_specific.psvd import (\n",
    "    read_and_clean_PSVD_data__BL_consensus,\n",
    "    categorize_PSVD_data,\n",
    "    exclude_patients,\n",
    "    reorder_some_categorical_values, \n",
    "    table1_psvd, \n",
    "    table1_psvd_spleen, \n",
    "    descriptive_df_from_masks, \n",
    "    masks_for_endpoint_1__decompensation, \n",
    "    masks_for_endpoint_2__death,\n",
    "    make_y_delta,\n",
    "    drop_non_numeric_columns,\n",
    "    table_of_valid_entries\n",
    ")\n",
    "\n",
    "# from cdata_utils.descriptive.utils import (\n",
    "#     get_occurencies,\n",
    "#     #get_distinct_values_summary\n",
    "# )\n",
    "\n",
    "\n",
    "from cdata_utils.descriptive.basic_stats import (\n",
    "    ordinal_numbers_frequency_str, \n",
    "    ordinal_numbers_frequency_ratio_str, \n",
    "    basic_stat_description,\n",
    "    BasicStats,\n",
    "    MEDIAN_IQR,\n",
    "    MEAN_SD,\n",
    "    N_PROCENT,\n",
    "    ORDINAL_0_to_1,\n",
    "    ORDINAL_1_to_2,\n",
    "    ORDINAL_1_to_3,\n",
    "    BasicStatsOrdinal,\n",
    "    BasicStatsOrdinalFractions,\n",
    "    ORDINAL_F_0_to_1,\n",
    "    ORDINAL_F_1_to_2,\n",
    "    ORDINAL_F_1_to_3,\n",
    "    generate_descriptive_table, \n",
    "    generate_descriptive_table_no_index,\n",
    "    describe\n",
    ")\n",
    "\n",
    "import cdata_utils.descriptive.basic_stats\n",
    "from cdata_utils.descriptive.basic_stats import (\n",
    "    basic_stat_description,\n",
    "    BasicStatsOrdinal\n",
    "    )\n",
    "\n",
    "from cdata_utils.utils import (\n",
    "    int_throw,\n",
    "    masks_are_all_mutually_exclusive, \n",
    "    union_of_masks_is_complete,\n",
    "    isdate_masks\n",
    ")\n",
    "\n",
    "# path info: \n",
    "if \"cwatzenboeck\" in os.getcwd(): # desktop \n",
    "    data_path = Path(\"/home/cwatzenboeck/Dropbox/work/data/livermodel/PSVD/\")\n",
    "    data_path_output=Path(\"/home/cwatzenboeck/data/psvd/output_coxph/\")\n",
    "else: # laptop \n",
    "    data_path = Path(\"/home/clemens/Dropbox/work/data/livermodel/PSVD/\")\n",
    "    # data_path = Path(\"/home/clemens/projects/project_liver_model/data/PSVD\")\n",
    "    \n",
    "    \n",
    "from cdata_utils.project_specific.psvd import (\n",
    "    rename_columns_by_prefix, \n",
    "    read_renaming_dict,\n",
    "    replace_,\n",
    "    read_and_clean_PSVD_data__BL_consensus_NEW,\n",
    "    load_EP1_EP2_data,\n",
    "    relevant_column_names,\n",
    "    relevant_column_names_clinical,\n",
    "    categorize_PSVD_clinical_data,\n",
    "    load_clinical_data,\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = load_EP1_EP2_data(data_path,  file_name = \"data_PSVD_unified_3.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df = read_and_clean_PSVD_data__BL_consensus_NEW(data_path=data_path, file_name = \"data_PSVD_unified_3.xlsx\", verbose=False, return_rename_dicts=False)\n",
    "\n",
    "# describe(df).iloc[[0,8,9,10,11],:].transpose() # check that unique values match expectation\n",
    "\n",
    "\n",
    "# describe(df).transpose().to_excel(data_path_output / \"describe_baseline_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = categorize_PSVD_data(df, drop_modfied_colums=True)\n",
    "# describe(df).iloc[8:,:].transpose() # check that unique values match expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# df = read_and_clean_PSVD_data__BL_consensus_NEW(data_path=data_path, file_name = \"data_PSVD_unified_3.xlsx\", verbose=False, return_rename_dicts=False)\n",
    "# # df, mapper_old2new, mapper_new2old = read_and_clean_PSVD_data__BL_consensus(data_path=data_path, file_name = \"data_PSVD_unified_3.xlsx\",   \n",
    "# #                                                                             verbose=False, return_rename_dicts=True)\n",
    "# df = reorder_some_categorical_values(df)\n",
    "\n",
    "# df = categorize_PSVD_data(df, drop_modfied_colums=True)\n",
    "    \n",
    "# c1 = \"1. Decompensation date\"; event_column=c1\n",
    "# df1 = make_y_delta(df, c1)\n",
    "# df_ = df1[[\"BL CT Date\", event_column, \"event\", \"status\"]]\n",
    "# masks_date = isdate_masks(df_, event_column)\n",
    "# df_[masks_date[\"zero\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data   # old data was \"data_PSVD_unified_1.xlsx\"\n",
    "\n",
    "# df = read_and_clean_PSVD_data__BL_consensus_NEW(data_path=data_path, file_name = \"data_PSVD_unified_3.xlsx\", verbose=False, return_rename_dicts=False)\n",
    "# # df, mapper_old2new, mapper_new2old = read_and_clean_PSVD_data__BL_consensus(data_path=data_path, file_name = \"data_PSVD_unified_3.xlsx\",   \n",
    "# #                                                                             verbose=False, return_rename_dicts=True)\n",
    "# df = reorder_some_categorical_values(df)\n",
    "\n",
    "# df = categorize_PSVD_data(df, drop_modfied_colums=True)\n",
    "    \n",
    "c1 = \"1. Decompensation date\"\n",
    "c2 = \"Death\"\n",
    "# df1 = make_y_delta(df, c1)\n",
    "# df2 = make_y_delta(df, c2)\n",
    "\n",
    "# # drop negative event cases: \n",
    "# m = df1[\"event\"] <= 0\n",
    "# if sum(m)>0: \n",
    "#     print(f\"Drop cases with negative time-to-event: \", list(df1[m][\"ID\"]), \" for EP1\")\n",
    "# df1 = df1[~m]\n",
    "\n",
    "# m = df2[\"event\"] <= 0\n",
    "# if sum(m)>0: \n",
    "#     print(f\"Drop cases with negative time-to-event: \", list(df2[m][\"ID\"]), \" for EP2\")\n",
    "# df2 = df2[~m]\n",
    "\n",
    "# df1 = drop_non_numeric_columns(df1)\n",
    "# df2 = drop_non_numeric_columns(df2)\n",
    "\n",
    "df1, df2 = load_EP1_EP2_data(data_path,  file_name = \"data_PSVD_unified_3.xlsx\")\n",
    "\n",
    "\n",
    "df1[\"event\"] = df1[\"event\"].apply(lambda x: float(x))\n",
    "df1[\"status\"] = df1[\"status\"].apply(lambda x: int(x))\n",
    "\n",
    "df2[\"event\"] = df2[\"event\"].apply(lambda x: float(x))\n",
    "df2[\"status\"] = df2[\"status\"].apply(lambda x: int(x))\n",
    "\n",
    "cc = ['BL Splanchnic thrombosis consensus binary cat. 1',\n",
    " 'BL Splanchnic thrombosis consensus binary cat. 2',\n",
    " 'BL Intrahepatic portal abnormalities consensus binary cat. 1',\n",
    " 'BL Intrahepatic portal abnormalities consensus binary cat. 2',\n",
    " 'BL Intrahepatic portal abnormalities consensus binary cat. 3',\n",
    " 'BL Intrahepatic portal abnormalities consensus binary cat. 4',\n",
    " 'BL Location consensus binary cat.']\n",
    "\n",
    "for c in cc: \n",
    "    df1[c] = df1[c].apply(int)\n",
    "    df2[c] = df2[c].apply(int)\n",
    "    \n",
    "df12 = df1.copy()\n",
    "df12 = df12.rename(columns={\"status\": f\"status EP={c1}\",\n",
    "                            \"event\":  f\"event EP={c1}\"})\n",
    "df12[f\"status EP={c2}\"] = df2[\"status\"]\n",
    "df12[f\"event EP={c2}\"]  = df2[\"event\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "describe(df12).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a lot of the patients the last visit is missing ... therfore they need to be excluded for the EP2 part\n",
    "# EP2 is however anyhow unlikely to work (to frew patients)\n",
    "# df2[df2[\"event\"].isnull()].filter(regex=\"Height|status|event|Death|Last Visit\")\n",
    "# table_of_valid_entries(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe(df1).to_excel(data_path / \"output\" / \"EP1_descompensation_desciption.xlsx\")\n",
    "# describe(df2).to_excel(data_path / \"output\" / \"EP2_death_desciption.xlsx\")\n",
    "# describe(df).to_excel(data_path / \"output\" / \"All_desciption.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_negative_times_to_event_cases = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical paramters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = load_EP1_EP2_data(data_path, file_name=\"data_PSVD_unified_3.xlsx\", drop_negative_times_to_event_cases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = load_clinical_data(data_path, file_name=\"data_PSVD_unified_3.xlsx\", drop_modfied_colums=True)\n",
    "# df1c = df1.join(df_c.drop(columns=['Sex (1=male, 2=female)']))\n",
    "# df2c = df2.join(df_c.drop(columns=['Sex (1=male, 2=female)']))\n",
    "\n",
    "\n",
    "# c1 = \"1. Decompensation date\"\n",
    "# c2 = \"Death\"\n",
    "# df1c = make_y_delta(df_c, c1)\n",
    "# df2c = make_y_delta(df_c, c2)\n",
    "\n",
    "\n",
    "\n",
    "# # drop negative event cases maybe: \n",
    "# m = df1c[\"event\"] <= 0\n",
    "# if drop_negative_times_to_event_cases and sum(m>0):\n",
    "#     df1c = df1c[~m]\n",
    "#     print(f\"Drop cases with negative time-to-event: \", list(df1c[m][\"ID\"]), \" for EP1\")\n",
    "# elif not drop_negative_times_to_event_cases and sum(m>0):\n",
    "#     print(f\"WARNING negative time-to-event: \", list(df1c[m][\"ID\"]), \" for EP1 were NOT dropped\")\n",
    "    \n",
    "\n",
    "# m = df2c[\"event\"] <= 0\n",
    "# if drop_negative_times_to_event_cases and sum(m>0):\n",
    "#     df2c = df2c[~m]\n",
    "#     print(f\"Drop cases with negative time-to-event: \", list(df2c[m][\"ID\"]), \" for EP2\")\n",
    "# elif not drop_negative_times_to_event_cases and sum(m>0):\n",
    "#     print(f\"WARNING negative time-to-event: \", list(df2c[m][\"ID\"]), \" for EP2 were NOT dropped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df_c.drop(columns=[\"Sex (1=male, 2=female)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
